{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're Gonna Need a Bigger Bot\n",
    "\n",
    "Let's map all the bits and pieces to a meatier example, to see how hello-ltr's abstractions make it easier to play with LTR via ipynbs\n",
    "\n",
    "Genome-tags is a crowdsourced movie tagging resource project. Each movie is assigned from 0-1 how close a movie matches a tag. Luckily the tags look remarkably like search queries (ie `star trek` or `berlin`). We derrived judgments from the genome-tags data, and use them to experiment with search.\n",
    "\n",
    "BUT\n",
    "\n",
    "While some tags are straight forward (`Star Trek`) others are much tougher (`boxing` or `french art movie`) where its unlikely any text has a match. \n",
    "\n",
    "We're not going to solve those problems here, but we give this to you as a sandbox to apply your skills after the class to see how close you can get to approximating the genome tags data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients \n",
    "\n",
    "While syntaxes differ, the LTR process is nearly identical between Solr and Elastic. So you can repeat a lot of the labs with Solr (some have been already translated)\n",
    "\n",
    "But we'll stick with Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:9201/_ltr; <OpenSearch([{'host': 'localhost', 'port': 9201}])>\n"
     ]
    }
   ],
   "source": [
    "from ltr.client import OpenSearchClient\n",
    "client = OpenSearchClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redownload corpus & judgments if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tmdb.json already exists\n",
      "GET http://es-learn-to-rank.labs.o19s.com/genome_judgments.txt\n"
     ]
    }
   ],
   "source": [
    "from ltr import download\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/genome_judgments.txt'\n",
    "\n",
    "download([corpus, judgments], dest='data/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindex if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index tmdb already exists. Use `force = True` to delete and recreate\n"
     ]
    }
   ],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Sets in ipynb\n",
    "\n",
    "You played with creating a feature set in the last lab, see the same process repeated here.\n",
    "\n",
    "Learning to rank requires creating feature set. Each feature has a name like `title_bm25` and as part of a list an ordinal `title_bm25` is the 0th item. Confusingly, Ranklib uses 1-based feature numbering, so feature 0 in this list corresponds to feature 1 in Ranklib training file, that we'll see soon.\n",
    "\n",
    "Notice also:\n",
    "\n",
    "- Each feature is a templated query with `{{keywords}}` parameter, that is passed at query time\n",
    "- We've added a `validation` block, which will run these queries with the specified parameters and index and return any query errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Default LTR feature store [Status: 200]\n",
      "Initialize Default LTR feature store [Status: 200]\n",
      "Create genome feature set [Status: 201]\n"
     ]
    }
   ],
   "source": [
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = {\n",
    "    \"featureset\": {\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"name\": \"title_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\n",
    "                        \"title\": \"{{keywords}}\"\n",
    "                    } \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"overview_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                        \"match\": {\n",
    "                            \"overview\": {\n",
    "                                \"query\": \"{{keywords}}\",\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"validation\": {\n",
    "              \"index\": \"tmdb\",\n",
    "              \"params\": {\n",
    "                  \"keywords\": \"rambo\"\n",
    "              }\n",
    "    \n",
    "           }\n",
    "}\n",
    "\n",
    "client.create_featureset(index='tmdb', name='genome', ftr_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Queries\n",
    "\n",
    "Logging is one of the more complex operations from an engineering perspective. \n",
    "\n",
    "The same query you ran manually when reviewing the slides is rerun here for every query in the source judgment list `judgmentInFile` with some batching when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 1128 queries\n"
     ]
    }
   ],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='genome')\n",
    "with judgments_open('data/genome_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here's where we train the model, under the hood this executes Ranklib just as you ran during the training exercises.\n",
    "\n",
    "Notice here we're optimizing for NDCG@10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/RankyMcRankFace.jar already exists\n",
      "Running java -jar /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/RankyMcRankFace.jar -ranker 6 -shrinkage 0.1 -metric2t NDCG@10 -tree 50 -bag 1 -leaf 10 -frate 1.0 -srate 1.0 -train /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/training.txt -save data/genome_model.txt \n",
      "Delete model genome: 404\n",
      "Created Model genome [Status: 201]\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from ltr.ranklib import train\n",
    "trainResponse = train(client,\n",
    "                 training_set=ftr_logger.logged,\n",
    "                 metric2t='NDCG@10',\n",
    "                 featureSet='genome',\n",
    "                 index='tmdb',\n",
    "                 modelName='genome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that training is done, we can output some statistics about the model, including the training metrics. In future units we'll get more into what this looks like.\n",
    "\n",
    "Notice the training NDCG isn't that great. When originally run, it was only 0.5885. So pretty far off of the genome data. One challenge of Learning to Rank (and Relevance in general) is trying to figure out the features that can close the gap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact of each feature on the model\n",
      "title_bm25 - 637582.3838513177\n",
      "overview_bm25 - 558539.450163617\n",
      "trainLog Metric 0.6801\n"
     ]
    }
   ],
   "source": [
    "print(\"Impact of each feature on the model\")\n",
    "trainLog = trainResponse.trainingLogs[0]\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(client.get_feature_name(config, ftrId), impact))\n",
    "    \n",
    "print(\"trainLog Metric %s\" % trainLog.metric())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with our model\n",
    "\n",
    "Here we're going to search using the `genome` model. You can see the LTR query being output (sent to Elasticsearch). You're encouraged to run that directly against Elasticsearch if you like.\n",
    "\n",
    "Please note, this isn't rescoring. And that's fine for our purposes of directly evaluating the model, in real life you really should run a rescore query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"size\": 5, \"query\": {\"sltr\": {\"params\": {\"keywords\": \"batman\", \"keywordsList\": [\"batman\"]}, \"model\": \"genome\"}}}\n",
      "{'size': 5, 'query': {'sltr': {'params': {'keywords': 'batman', 'keywordsList': ['batman']}, 'model': 'genome'}}}\n",
      "Batman: Under the Red Hood \n",
      "4.059837 \n",
      "2010 \n",
      "['Action', 'Animation'] \n",
      "Batman faces his ultimate challenge as the mysterious Red Hood takes Gotham City by firestorm. One part vigilante, one part criminal kingpin, Red Hood begins cleaning up Gotham with the efficiency of Batman, but without following the same ethical code. \n",
      "---------------------------------------\n",
      "Batman: The Dark Knight Returns, Part 2 \n",
      "4.0364103 \n",
      "2013 \n",
      "['Animation', 'Action'] \n",
      "Batman has stopped the reign of terror that The Mutants had cast upon his city.  Now an old foe wants a reunion and the government wants The Man of Steel to put a stop to Batman. \n",
      "---------------------------------------\n",
      "Batman Returns \n",
      "4.0364103 \n",
      "1992 \n",
      "['Action', 'Crime', 'Fantasy', 'Science Fiction', 'Thriller'] \n",
      "Having defeated the Joker, Batman now faces the Penguin - a warped and deformed individual who is intent on being accepted into Gotham society. Crooked businessman Max Schreck is coerced into helping him become Mayor of Gotham and they both attempt to expose Batman in a different light. Selina Kyle, Max's secretary, is thrown from the top of a building and is transformed into Catwoman - a mysterious figure who has the same personality disorder as Batman. Batman must attempt to clear his name, all the time deciding just what must be done with the Catwoman. \n",
      "---------------------------------------\n",
      "Batman Unmasked: The Psychology of the Dark Knight \n",
      "4.0364103 \n",
      "2008 \n",
      "['Documentary'] \n",
      "Delve into the world of Batman and the vigilante justice that he brought to the city of Gotham. Batman is a man who, after experiencing great tragedy, devotes his life to an ideal--but what happens when one man takes on the evil underworld alone? Examine why Batman is who he is--and explore how a boy scarred by tragedy becomes a symbol of hope to everyone else. \n",
      "---------------------------------------\n",
      "Batman and Robin \n",
      "3.8168392 \n",
      "1949 \n",
      "['Action', 'Science Fiction', 'Thriller'] \n",
      "This 15-chapter serial pits Batman and Robin against The Wizard, who uses a device that allows him to control machinery to hold the city hostage. \n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ltr import search\n",
    "search(client, \"batman\", modelName='genome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
