{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization on OpenSearch Boosts & Params\n",
    "\n",
    "This notebook is from Doug Turnbull's [Twitch Livecoding](https://www.twitch.tv/videos/1236075888) where he live-coded bayesian optimization. It's messy code that you'd expect from a live coding session, so caveat emptor :)\n",
    "\n",
    "Bibliography & Further reading\n",
    "\n",
    "* [Exploring Bayesian Optimization](https://distill.pub/2020/bayesian-optimization) by Apoorv Agnihotri and Nipun Batra of the Indian Institute of Technology Gandhinagar\n",
    "* [Improving search relevance with data-driven query optimization](https://www.elastic.co/blog/improving-search-relevance-with-data-driven-query-optimization) by Josh Devins, Senior Principal Engineer, Elastic\n",
    "* [AI Powered Search](http://aipoweredsearch) by Trey Grainger, Doug Turnbull, and Max Irwin. In particular chapter 12 uses Bayesian Optimization techniquest to overcome presentation bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Indexing\n",
    "\n",
    "We are using [TheMovieDB](http://themoviedb.org) corpus. Download and index that to the local Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import OpenSearchClient\n",
    "client = OpenSearchClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tmdb.json already exists\n",
      "data/title_judgments.txt already exists\n"
     ]
    }
   ],
   "source": [
    "from ltr import download\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments.txt'\n",
    "\n",
    "download([corpus, judgments], dest='data/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index tmdb already exists. Use `force = True` to delete and recreate\n"
     ]
    }
   ],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "grade/label, query, doc_id\n",
    "```\n",
    "\n",
    "grade = 0-4 with 0 completely irrelevant, 4 absolutely relevant\n",
    "query = rambo\n",
    "doc_id = movie id \"tmdb id\"\n",
    "\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a simple movie judgment list\n",
    "\n",
    "These judgments have a grade (0-4) that says how relevant a movie is (the 'doc id') for a query (ie 'rambo', etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 40 queries\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'f', 'judgments', 'keywords', 'kw_with_weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markcoh/IdeaProjects/OpenSearchWork/hello-ltr/ltr/judgments.py:266: FutureWarning:\n",
      "\n",
      "In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>qid</th>\n",
       "      <th>keywords</th>\n",
       "      <th>docId</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_7555</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>7555</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1370</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1370</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1369</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1369</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_13258</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>13258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_1368</td>\n",
       "      <td>1</td>\n",
       "      <td>rambo</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>40_37079</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>37079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>40_126757</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>126757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>40_39797</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>39797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>40_18112</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>18112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>40_43052</td>\n",
       "      <td>40</td>\n",
       "      <td>star wars</td>\n",
       "      <td>43052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uid  qid   keywords   docId  grade\n",
       "0        1_7555    1      rambo    7555      4\n",
       "1        1_1370    1      rambo    1370      3\n",
       "2        1_1369    1      rambo    1369      3\n",
       "3       1_13258    1      rambo   13258      2\n",
       "4        1_1368    1      rambo    1368      4\n",
       "...         ...  ...        ...     ...    ...\n",
       "1385   40_37079   40  star wars   37079      0\n",
       "1386  40_126757   40  star wars  126757      0\n",
       "1387   40_39797   40  star wars   39797      0\n",
       "1388   40_18112   40  star wars   18112      0\n",
       "1389   40_43052   40  star wars   43052      0\n",
       "\n",
       "[1390 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open, judgments_to_dataframe\n",
    "from itertools import groupby\n",
    "\n",
    "judgments_dataframe = None\n",
    "\n",
    "with judgments_open('data/title_judgments.txt') as judgment_list:\n",
    "    print(dir(judgment_list))\n",
    "    judgments_dataframe = judgments_to_dataframe(judgment_list)\n",
    "    \n",
    "judgments_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCG - discounted cumulative gain\n",
    "# ERR, MRR, etc\n",
    "# Cumulative Gain - Precision\n",
    "#  - sum of the top N grades for a result set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7555': {'uid': '1_7555',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '7555',\n",
       "  'grade': 4},\n",
       " '1370': {'uid': '1_1370',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '1370',\n",
       "  'grade': 3},\n",
       " '1369': {'uid': '1_1369',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '1369',\n",
       "  'grade': 3},\n",
       " '13258': {'uid': '1_13258',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '13258',\n",
       "  'grade': 2},\n",
       " '1368': {'uid': '1_1368',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '1368',\n",
       "  'grade': 4},\n",
       " '31362': {'uid': '1_31362',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '31362',\n",
       "  'grade': 1},\n",
       " '61410': {'uid': '1_61410',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '61410',\n",
       "  'grade': 1},\n",
       " '319074': {'uid': '1_319074',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '319074',\n",
       "  'grade': 0},\n",
       " '10296': {'uid': '1_10296',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '10296',\n",
       "  'grade': 0},\n",
       " '35868': {'uid': '1_35868',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '35868',\n",
       "  'grade': 0},\n",
       " '131457': {'uid': '1_131457',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '131457',\n",
       "  'grade': 0},\n",
       " '94794': {'uid': '1_94794',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '94794',\n",
       "  'grade': 0},\n",
       " '169869': {'uid': '1_169869',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '169869',\n",
       "  'grade': 0},\n",
       " '34561': {'uid': '1_34561',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '34561',\n",
       "  'grade': 0},\n",
       " '13763': {'uid': '1_13763',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '13763',\n",
       "  'grade': 0},\n",
       " '62414': {'uid': '1_62414',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '62414',\n",
       "  'grade': 0},\n",
       " '21989': {'uid': '1_21989',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '21989',\n",
       "  'grade': 0},\n",
       " '210577': {'uid': '1_210577',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '210577',\n",
       "  'grade': 0},\n",
       " '56949': {'uid': '1_56949',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '56949',\n",
       "  'grade': 0},\n",
       " '79401': {'uid': '1_79401',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '79401',\n",
       "  'grade': 0},\n",
       " '117942': {'uid': '1_117942',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '117942',\n",
       "  'grade': 0},\n",
       " '223195': {'uid': '1_223195',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '223195',\n",
       "  'grade': 0},\n",
       " '70': {'uid': '1_70',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '70',\n",
       "  'grade': 0},\n",
       " '22777': {'uid': '1_22777',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '22777',\n",
       "  'grade': 0},\n",
       " '43189': {'uid': '1_43189',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '43189',\n",
       "  'grade': 0},\n",
       " '318': {'uid': '1_318',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '318',\n",
       "  'grade': 0},\n",
       " '39829': {'uid': '1_39829',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '39829',\n",
       "  'grade': 0},\n",
       " '208982': {'uid': '1_208982',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '208982',\n",
       "  'grade': 1},\n",
       " '250761': {'uid': '1_250761',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '250761',\n",
       "  'grade': 1},\n",
       " '801': {'uid': '1_801',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '801',\n",
       "  'grade': 1},\n",
       " '78999': {'uid': '1_78999',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '78999',\n",
       "  'grade': 1},\n",
       " '600': {'uid': '1_600',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '600',\n",
       "  'grade': 1},\n",
       " '26397': {'uid': '1_26397',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '26397',\n",
       "  'grade': 0},\n",
       " '45046': {'uid': '1_45046',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '45046',\n",
       "  'grade': 0},\n",
       " '271110': {'uid': '1_271110',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '271110',\n",
       "  'grade': 0},\n",
       " '59401': {'uid': '1_59401',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '59401',\n",
       "  'grade': 0},\n",
       " '79773': {'uid': '1_79773',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '79773',\n",
       "  'grade': 0},\n",
       " '321': {'uid': '1_321',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '321',\n",
       "  'grade': 0},\n",
       " '11553': {'uid': '1_11553',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '11553',\n",
       "  'grade': 0},\n",
       " '32221': {'uid': '1_32221',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '32221',\n",
       "  'grade': 0},\n",
       " '40082': {'uid': '1_40082',\n",
       "  'qid': 1,\n",
       "  'keywords': 'rambo',\n",
       "  'docId': '40082',\n",
       "  'grade': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{judgment['docId']: judgment for judgment in judgments_dataframe['rambo' == judgments_dataframe['keywords']].to_dict('records')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a query template using average CG@10\n",
    "\n",
    "We use a parameteried query 'template' (where we do the replacement here) and see what the Cumulative Gain (average relevance grade) for the solution across all queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825000000000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_and_evaluate(judgments, es_query, at=10, params={}):\n",
    "    query = json.dumps(es_query)\n",
    "    \n",
    "    for param, value in params.items():\n",
    "        query = query.replace(\"{{\" + param + \"}}\", str(value))\n",
    "   \n",
    "    es_query = json.loads(query)\n",
    "    \n",
    "    average_cumulative_gain = 0.0\n",
    "    \n",
    "    for keywords in judgments['keywords'].unique():\n",
    "        query = json.dumps(es_query).replace(\"{{keywords}}\", keywords)\n",
    "        query = json.loads(query)\n",
    "        \n",
    "        # print(json.dumps(query))\n",
    "     \n",
    "        results = client.es.search(index='tmdb', body=query)\n",
    "        # print(keywords)\n",
    "        # print('-----')\n",
    "        this_keyword_judgments = {judgment['docId']: judgment \n",
    "                                  for judgment in \n",
    "                                  judgments[keywords == judgments['keywords']].to_dict('records')}\n",
    "        cumulative_gain = 0 \n",
    "        for idx, hit in enumerate(results['hits']['hits']):\n",
    "            this_grade = 0.0\n",
    "            try:\n",
    "                this_grade = this_keyword_judgments[hit['_id']]['grade']\n",
    "                cumulative_gain += this_grade\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if idx >= at:\n",
    "                break\n",
    "\n",
    "            # print(hit['_source']['title'], this_grade)\n",
    "            \n",
    "        cumulative_gain /= at   # < now this is the average grade for top at\n",
    "        average_cumulative_gain += cumulative_gain\n",
    "        \n",
    "        # print(f\"CG@10 {cumulative_gain}\")\n",
    "        # print()\n",
    "    return average_cumulative_gain / len(judgments['keywords'].unique())\n",
    "        \n",
    "search_and_evaluate(judgments_dataframe, es_query={'query': {'match': {'title': '{{keywords}}'}}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple query template to optimize\n",
    "\n",
    "Query template to optimize\n",
    "\n",
    "Notice the naive grid search (two for loops) would be too slow if we tried every value. Running every scenario against Elasticsearch would be too slow. So we prime our optimization with a handful of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "--- RUN 0.36500000000000005 {'title_boost': 0, 'overview_boost': 0}\n",
      "-----------------------------------------\n",
      "--- RUN 0.4675000000000001 {'title_boost': 0, 'overview_boost': 50}\n",
      "-----------------------------------------\n",
      "--- RUN 0.4675000000000001 {'title_boost': 0, 'overview_boost': 100}\n",
      "-----------------------------------------\n",
      "--- RUN 0.4675000000000001 {'title_boost': 0, 'overview_boost': 150}\n",
      "-----------------------------------------\n",
      "--- RUN 0.9100000000000001 {'title_boost': 50, 'overview_boost': 0}\n",
      "-----------------------------------------\n",
      "--- RUN 0.8724999999999999 {'title_boost': 50, 'overview_boost': 50}\n",
      "-----------------------------------------\n",
      "--- RUN 0.6775 {'title_boost': 50, 'overview_boost': 100}\n",
      "-----------------------------------------\n",
      "--- RUN 0.63 {'title_boost': 50, 'overview_boost': 150}\n",
      "-----------------------------------------\n",
      "--- RUN 0.9100000000000001 {'title_boost': 100, 'overview_boost': 0}\n",
      "-----------------------------------------\n",
      "--- RUN 0.9525 {'title_boost': 100, 'overview_boost': 50}\n",
      "-----------------------------------------\n",
      "--- RUN 0.8724999999999999 {'title_boost': 100, 'overview_boost': 100}\n",
      "-----------------------------------------\n",
      "--- RUN 0.72 {'title_boost': 100, 'overview_boost': 150}\n",
      "-----------------------------------------\n",
      "--- RUN 0.9100000000000001 {'title_boost': 150, 'overview_boost': 0}\n",
      "-----------------------------------------\n",
      "--- RUN 0.9400000000000001 {'title_boost': 150, 'overview_boost': 50}\n",
      "-----------------------------------------\n",
      "--- RUN 0.9325000000000001 {'title_boost': 150, 'overview_boost': 100}\n",
      "-----------------------------------------\n",
      "--- RUN 0.8724999999999999 {'title_boost': 150, 'overview_boost': 150}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title_boost': 100, 'overview_boost': 50, 'mean_cg': 0.9525},\n",
       " {'title_boost': 150, 'overview_boost': 50, 'mean_cg': 0.9400000000000001},\n",
       " {'title_boost': 150, 'overview_boost': 100, 'mean_cg': 0.9325000000000001},\n",
       " {'title_boost': 50, 'overview_boost': 0, 'mean_cg': 0.9100000000000001},\n",
       " {'title_boost': 100, 'overview_boost': 0, 'mean_cg': 0.9100000000000001},\n",
       " {'title_boost': 150, 'overview_boost': 0, 'mean_cg': 0.9100000000000001},\n",
       " {'title_boost': 50, 'overview_boost': 50, 'mean_cg': 0.8724999999999999},\n",
       " {'title_boost': 100, 'overview_boost': 100, 'mean_cg': 0.8724999999999999},\n",
       " {'title_boost': 150, 'overview_boost': 150, 'mean_cg': 0.8724999999999999},\n",
       " {'title_boost': 100, 'overview_boost': 150, 'mean_cg': 0.72},\n",
       " {'title_boost': 50, 'overview_boost': 100, 'mean_cg': 0.6775},\n",
       " {'title_boost': 50, 'overview_boost': 150, 'mean_cg': 0.63},\n",
       " {'title_boost': 0, 'overview_boost': 50, 'mean_cg': 0.4675000000000001},\n",
       " {'title_boost': 0, 'overview_boost': 100, 'mean_cg': 0.4675000000000001},\n",
       " {'title_boost': 0, 'overview_boost': 150, 'mean_cg': 0.4675000000000001},\n",
       " {'title_boost': 0, 'overview_boost': 0, 'mean_cg': 0.36500000000000005}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "es_query={'query':\n",
    "  {\n",
    "      \"bool\": {\n",
    "          \"should\": [\n",
    "              {'match': \n",
    "                  {'title': \n",
    "                     {\n",
    "                       'query': '{{keywords}}',\n",
    "                       'boost': '{{title_boost}}'\n",
    "                     }\n",
    "\n",
    "                   }\n",
    "              },\n",
    "              {'match': \n",
    "                  {'overview': \n",
    "                     {\n",
    "                       'query': '{{keywords}}',\n",
    "                       'boost': '{{overview_boost}}'\n",
    "                     }\n",
    "\n",
    "                   }\n",
    "              }\n",
    "          ]\n",
    "      }\n",
    "  }\n",
    "   \n",
    "}\n",
    "\n",
    "\n",
    "# Grid search\n",
    "\n",
    "runs = []\n",
    "for title_boost in range(0,200,50):  # Random -> Generate random value\n",
    "    for overview_boost in range(0, 200, 50):\n",
    "        print(\"-----------------------------------------\")\n",
    "        params={'title_boost': title_boost, 'overview_boost': overview_boost}\n",
    "        avg_cg = search_and_evaluate(judgments_dataframe, es_query=es_query, \n",
    "                                     params=params)\n",
    "        print(f\"--- RUN {avg_cg} {repr(params)}\")\n",
    "        \n",
    "        runs.append({**params, **{'mean_cg': avg_cg}})\n",
    "              \n",
    "sorted_by_perf = sorted(runs, key=lambda value: value['mean_cg'], reverse=True)\n",
    "sorted_by_perf\n",
    "# 40,000 * k queries we're hitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Gaussian Process on runs so far\n",
    "\n",
    "We want to learn the best places to explore for more optimal relevance (`mean_cg`). So we train a [Gaussian Process](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html) to learn CG as a function of the parameters (`title_boost`, `overview_boost`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import pandas as pd\n",
    "\n",
    "runs_so_far = pd.DataFrame(sorted_by_perf)\n",
    "\n",
    "y_train = runs_so_far['mean_cg']\n",
    "x_train = runs_so_far[['title_boost', 'overview_boost']]\n",
    "\n",
    "\n",
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(x_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gaussian Process gives us BOTH uncertainty and prediction\n",
    "\n",
    "A GaussianProcess learns BOTH a prediction and the uncertainty of that prediction. As we move farther from the training data, the prediction becomes less certain.\n",
    "\n",
    "On any given data point we can get the prediction and the uncertainty in that prediction (as standard deviation of the prediction at that point).\n",
    "\n",
    "First we look at a value we trained on, notice the very low std deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prediction, std_dev = gpr.predict([[100.0, 50.0]], return_std=True)\n",
    "prediction, std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more uncertainty in values we haven't seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, std_dev = gpr.predict([[300.0, 50.0]], return_std=True)\n",
    "prediction, std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization - find wher eto explore\n",
    "\n",
    "With a series of probe points, we can see the prediction and standard deviations in a Pandas Dataframe below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_point = np.array([[0.0, 150.0], [45.0, 175.0]])\n",
    "probe_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, std_devs = gpr.predict(probe_point, return_std=True)\n",
    "\n",
    "\n",
    "together = []\n",
    "for i in range(len(predictions)):\n",
    "    together.append({'prediction': predictions[i],\n",
    "                     'std_dev': std_devs[i]})\n",
    "    \n",
    "\n",
    "explore_points = pd.DataFrame(together) \n",
    "explore_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of improvement Scoring\n",
    "\n",
    "The goal of Bayesian Optimization is to score the value of one of the probe points for more expensive probing with Elasticsearch. The idea is we have a cheap model that can give us a guess (the Gaussian Process) and an expensive way to get a ground truth (run many queries against Elasticsearch).\n",
    "\n",
    "We'll score using the probability of improvement. The first componend is the `opportunity` - how much would be gained by the current prediction (regardless of the uncertainty in that prediction).\n",
    "\n",
    "We add that to the dataframe here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cg = 0.9525  # Best CG we've seen in the current data points\n",
    "\n",
    "explore_points['opportunity'] = explore_points['prediction'] - best_cg\n",
    "explore_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide by std dev to get the prob of improvement\n",
    "\n",
    "If the uncertainty is high, then the value approaches 0. If the uncertainty is low, then the value increases quite a bit. \n",
    "\n",
    "`norm.cdf` scales this between 0-1 to give us more of a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "std_dev = 0.00000001\n",
    "\n",
    "norm.cdf( (explore_points['opportunity']) / std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.999999\n",
    "\n",
    "norm.cdf( (explore_points['opportunity']) / std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob of improvement for each `explore_point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf( explore_points['opportunity'] / explore_points['std_dev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score 40k points to find best explore points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probe_point = np.array([[0.0, 150.0], [45.0, 175.0]])\n",
    "probes = []\n",
    "for title_boost in range(0,200,1):  # Random -> Generate random value\n",
    "    for overview_boost in range(0, 200, 1):\n",
    "        probes.append([title_boost, overview_boost])\n",
    "        \n",
    "probes = pd.DataFrame(probes, columns=['title_boost', 'overview_boost'])\n",
    "\n",
    "predictions, std_devs = gpr.predict(probes, return_std=True)\n",
    "\n",
    "predictions, std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = []\n",
    "for i in range(len(predictions)):\n",
    "    together.append({'prediction': predictions[i],\n",
    "                     'std_dev': std_devs[i]})\n",
    "    \n",
    "\n",
    "explore_points = pd.DataFrame(together) \n",
    "explore_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theta is used as an explore / exploit parameter\n",
    "\n",
    "Higher theta means we drown out the opportunity, and we bias towards exploring untried points. Lower theta means we try areas close to areas we've already explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cg = 0.9525\n",
    "\n",
    "theta = 20.0\n",
    "explore_points['opportunity'] = explore_points['prediction'] - best_cg - theta\n",
    "explore_points\n",
    "\n",
    "explore_points.sort_values(by='opportunity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe highest probability of improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_points['prob_of_improvement'] = norm.cdf( explore_points['opportunity'] / explore_points['std_dev'])\n",
    "explore_points.sort_values(by='prob_of_improvement', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_places_to_try = explore_points.sort_values(by='prob_of_improvement', ascending=False).head(10)\n",
    "top_places_to_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probes = probes.loc[top_places_to_try.index]\n",
    "best_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take top N best to Elasticsearch\n",
    "\n",
    "We can now try the highest scored probe points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probes = best_probes.to_dict(orient='records')\n",
    "\n",
    "for probe in best_probes:\n",
    "    print(probe)\n",
    "    print(\"-----------------------------------------\")\n",
    "    avg_cg = search_and_evaluate(judgments_dataframe, es_query=es_query, \n",
    "                                 params=probe)\n",
    "    print(f\"--- RUN {avg_cg} {repr(params)}\")\n",
    "\n",
    "    runs.append({**probe, **{'mean_cg': avg_cg}})\n",
    "              \n",
    "sorted_by_perf = sorted(runs, key=lambda value: value['mean_cg'], reverse=True)\n",
    "sorted_by_perf\n",
    "\n",
    "sorted_by_perf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Gaussian Process on every direct observation\n",
    "\n",
    "We repeat the process by retraining the Gaussian Process on **every observation thusfar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import pandas as pd\n",
    "\n",
    "runs_so_far = pd.DataFrame(sorted_by_perf)\n",
    "\n",
    "y_train = runs_so_far['mean_cg']\n",
    "x_train = runs_so_far[['title_boost', 'overview_boost']]\n",
    "\n",
    "\n",
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(x_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat prob of improvement scoring, reprobe Elasticsearch, etc\n",
    "\n",
    "Now we repeat the scoring on the Gaussian Process trained on this larger dataset. With more data, we can probe more accurately. Repeat until you feel you get a sense of the optimum :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "* Probability of Improvement is usually not the preferred scoring. It just computes a probability. But what you really want is sto get the **expected improvement**. A score that accounts for cases where the improvement would be dramatically higher. So a low probability of a high increase in our relevance stat - CG - might be scored higher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
