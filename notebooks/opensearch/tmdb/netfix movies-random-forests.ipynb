{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenSearch Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import OpenSearchClient\n",
    "client = OpenSearchClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download & Build Index (run once)\n",
    "\n",
    "If you don't already have the downloaded dependencies; if you don't have TheMovieDB data indexed run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tmdb.json already exists\n",
      "data/title_judgments.txt already exists\n",
      "Index tmdb already exists. Use `force = True` to delete and recreate\n"
     ]
    }
   ],
   "source": [
    "def add_collection_name(src_movie, base_doc):\n",
    "    if 'belongs_to_collection' in src_movie and src_movie['belongs_to_collection'] is not None:\n",
    "        if 'name' in src_movie['belongs_to_collection']:\n",
    "            base_doc['collection_name'] = src_movie['belongs_to_collection']['name']\n",
    "    return base_doc\n",
    "\n",
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "from ltr import download\n",
    "\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments.txt'\n",
    "download([corpus, judgments], dest='data/');\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json', enrich=add_collection_name)\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for movie titles\n",
    "\n",
    "We'll be searching movie titles (think searching for a specific movie on Netflix). And we have a set of judgments around the appropriatte movie to return. IE search for \"Star Wars\" return good star wars matches, in quality order...\n",
    "\n",
    "These cover various aspects of the problem (searching title by phrase, title bm25 score, release date, etc). We'll use this to explore and analyze a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Default LTR feature store [Status: 200]\n",
      "Initialize Default LTR feature store [Status: 200]\n",
      "Create title_rf feature set [Status: 201]\n"
     ]
    }
   ],
   "source": [
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = {\"validation\": {\n",
    "              \"index\": \"tmdb\",\n",
    "              \"params\": {\n",
    "                  \"keywords\": \"rambo\"\n",
    "              }\n",
    "    \n",
    "           },\n",
    "           \"featureset\": {\n",
    "            \"features\": [\n",
    "            {\n",
    "                \"name\": \"title_phrase\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"constant_score\": {\n",
    "                        \"filter\": {\n",
    "                            \"match_phrase\": {\"title\": \"{{keywords}}\"}\n",
    "                        },\n",
    "                        \"boost\": 1.0\n",
    "                    }  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"title\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"constant_score\": {\n",
    "                        \"filter\": {\n",
    "                            \"match\": {\"title\": \"{{keywords}}\"}\n",
    "                        },\n",
    "                        \"boost\": 1.0\n",
    "                    }  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"title_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"title\": \"{{keywords}}\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"overview_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"overview\": \"{{keywords}}\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"overview_phrase_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match_phrase\": {\"overview\": \"{{keywords}}\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"title_fuzzy\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"title\": \n",
    "                                {\"query\": \"{{keywords}}\",\n",
    "                                 \"fuzziness\": \"AUTO\"}}\n",
    "                }\n",
    "            },\n",
    "             {\n",
    "                \"name\": \"release_year\",\n",
    "                \"params\": [],\n",
    "                \"template\": {\n",
    "                    \"function_score\": {\n",
    "                        \"field_value_factor\": {\n",
    "                            \"field\": \"release_year\",\n",
    "                            \"missing\": 2000\n",
    "                        },\n",
    "                        \"query\": { \"match_all\": {} }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"coll_name_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"collection_name\": \n",
    "                                {\"query\": \"{{keywords}}\"}}\n",
    "                }\n",
    "            },\n",
    "             {\n",
    "                \"name\": \"coll_name_phrase_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match_phrase\": {\"collection_name\": \n",
    "                                {\"query\": \"{{keywords}}\"}}\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            \n",
    "            ]\n",
    "    }}\n",
    "\n",
    "\n",
    "client.create_featureset(index='tmdb', name='title_rf', ftr_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Generation\n",
    "\n",
    "Log out features for each of the above queries out to a training set file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 40 queries\n"
     ]
    }
   ],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='title_rf')\n",
    "with judgments_open('data/title_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Selections\n",
    "\n",
    "Feature searches are very time consuming for anything other than trivial data. To deal with feature dependencies, one strategy is to select a random subset of features at every decision tree split for consideration. This prevents overfitting and allows feature impacts to give a more accurate impact to how they effect the relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/RankyMcRankFace.jar already exists\n",
      "Running java -jar /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/RankyMcRankFace.jar -ranker 8 -shrinkage 0.1 -metric2t NDCG@10 -tree 100 -bag 1 -leaf 4 -frate 0.5 -srate 1.0 -train /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/training.txt -save data/title_rf_model.txt  -feature /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/features.txt -kcv 5 \n",
      "\n",
      "Impact of each feature on the model\n",
      "title_fuzzy - 58.98475855415306\n",
      "title_bm25 - 2.270030212189714\n",
      "overview_bm25 - 0.5272996580514282\n",
      "Test NDCG@10 0.8597\n"
     ]
    }
   ],
   "source": [
    "from ltr.ranklib import train\n",
    "res  = train(client,\n",
    "            training_set=ftr_logger.logged,\n",
    "            metric2t='NDCG@10',\n",
    "            leafs=4,\n",
    "            trees=100,\n",
    "            ranker=8, # Use a \"Random Forests Model\"\n",
    "            frate=0.5,\n",
    "            bag=1, # Number of ensembles in the forest bag=1, 1 LambdaMART model with random features chosen\n",
    "            index='tmdb',\n",
    "            kcv=5,\n",
    "            features=[1,2,3,4,5,6,7,8,9],\n",
    "            featureSet='title_rf',\n",
    "            modelName='title_rf')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in res.trainingLogs[0].impacts.items():\n",
    "    print(\"{} - {}\".format(client.get_feature_name(config, ftrId), impact))\n",
    "    \n",
    "    \n",
    "print(\"Test NDCG@10 %s\" % res.kcvTestAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/RankyMcRankFace.jar already exists\n",
      "Running java -jar /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/RankyMcRankFace.jar -ranker 8 -shrinkage 0.1 -metric2t NDCG@10 -tree 100 -bag 3 -leaf 4 -frate 0.5 -srate 1.0 -train /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/training.txt -save data/title_rf_model.txt  -feature /var/folders/33/jx0mw87156q2hmtrr_r82s7r0000gs/T/features.txt\n",
      "Delete model title_rf: 404\n",
      "Created Model title_rf [Status: 201]\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from ltr.ranklib import train\n",
    "res  = train(client,\n",
    "             training_set=ftr_logger.logged,\n",
    "             metric2t='NDCG@10',\n",
    "             leafs=4,\n",
    "             trees=100,\n",
    "             ranker=8, # Use a \"Random Forests Model\"\n",
    "             frate=0.5,\n",
    "             bag=3, # Number of ensembles in the forest bag=1, 1 LambdaMART model with random features chosen\n",
    "             index='tmdb',\n",
    "             features=[1,2,3,4,5,6,7,8,9],\n",
    "             featureSet='title_rf',\n",
    "             modelName='title_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
